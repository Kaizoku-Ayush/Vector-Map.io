{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f38155e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete!\n",
      "PyTorch version: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "GPU Memory: 8.0GB\n"
     ]
    }
   ],
   "source": [
    "# Environment Setup and Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Dask for distributed processing\n",
    "import dask\n",
    "from dask import delayed\n",
    "from dask.distributed import Client\n",
    "import multiprocessing as mp\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b904278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model initialized with parameters: 43,228,098\n",
      "Loading weights from height_analysis_output/best_height_model.pth\n",
      "Model weights loaded successfully!\n",
      "Model ready for large-scale processing!\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model architecture classes\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Double convolution block with BatchNorm and ReLU\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downsampling block with maxpool followed by double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upsampling block with transpose conv and skip connections\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # Handle Size Mismatch\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = nn.functional.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                                    diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        # Concatenate skip connection\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        \n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    \"\"\"Final output convolution\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNetWithHeight(nn.Module):\n",
    "    \"\"\"Enhanced U-Net with height estimation capabilities\"\"\"\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNetWithHeight, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Encoder\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        \n",
    "        # Decoder for segmentation\n",
    "        self.up1 = Up(1024, 512)\n",
    "        self.up2 = Up(512, 256)\n",
    "        self.up3 = Up(256, 128)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "        \n",
    "        # Height estimation branch\n",
    "        self.height_up1 = Up(1024, 512)\n",
    "        self.height_up2 = Up(512, 256)\n",
    "        self.height_up3 = Up(256, 128)\n",
    "        self.height_up4 = Up(128, 64)\n",
    "        self.height_out = OutConv(64, 1)  # Single channel for height\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        # Segmentation decoder path\n",
    "        seg_x = self.up1(x5, x4)\n",
    "        seg_x = self.up2(seg_x, x3)\n",
    "        seg_x = self.up3(seg_x, x2)\n",
    "        seg_x = self.up4(seg_x, x1)\n",
    "        segmentation = self.outc(seg_x)\n",
    "        \n",
    "        # Height estimation decoder path\n",
    "        height_x = self.height_up1(x5, x4)\n",
    "        height_x = self.height_up2(height_x, x3)\n",
    "        height_x = self.height_up3(height_x, x2)\n",
    "        height_x = self.height_up4(height_x, x1)\n",
    "        height_map = self.height_out(height_x)\n",
    "        \n",
    "        return segmentation, height_map\n",
    "\n",
    "# Initialize the correct model architecture\n",
    "model = UNetWithHeight(n_channels=3, n_classes=1).to(device)\n",
    "print(f\"Model initialized with parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "def load_model_weights(model, checkpoint_path):\n",
    "    \"\"\"Load model weights from checkpoint\"\"\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"Warning: Checkpoint {checkpoint_path} not found. Using random weights.\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"Loading weights from {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    \n",
    "    model.eval()\n",
    "    print(\"Model weights loaded successfully!\")\n",
    "    return True\n",
    "\n",
    "model_loaded = load_model_weights(model, \"height_analysis_output/best_height_model.pth\")\n",
    "print(\"Model ready for large-scale processing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b403765d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Image large_area_1.tif not found, creating dummy entry\n",
      "Warning: Image large_area_2.tif not found, creating dummy entry\n",
      "Created large-scale dataset with 23328 patches\n",
      "Dataset ready for 500km x 500km processing!\n"
     ]
    }
   ],
   "source": [
    "# Large-Scale Dataset for 500km x 500km Areas\n",
    "class LargeScaleDataset(Dataset):\n",
    "    \"\"\"Dataset designed for processing very large satellite imagery (500km x 500km)\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, patch_size=512, overlap=0.1, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.patch_size = patch_size\n",
    "        self.overlap = overlap\n",
    "        self.transform = transform\n",
    "        self.patches_info = []\n",
    "        self._calculate_patches()\n",
    "    \n",
    "    def _calculate_patches(self):\n",
    "        \"\"\"Calculate all patches for efficient large-scale processing\"\"\"\n",
    "        step = int(self.patch_size * (1 - self.overlap))\n",
    "        \n",
    "        for img_idx, img_path in enumerate(self.image_paths):\n",
    "            if not Path(img_path).exists():\n",
    "                print(f\"Warning: Image {img_path} not found, creating dummy entry\")\n",
    "                # Create dummy large image dimensions for 500km x 500km\n",
    "                h, w = 50000, 50000  # Very large image simulation\n",
    "            else:\n",
    "                img = Image.open(img_path)\n",
    "                w, h = img.size\n",
    "            \n",
    "            # Calculate patches for this large image\n",
    "            for y in range(0, h - self.patch_size + 1, step):\n",
    "                for x in range(0, w - self.patch_size + 1, step):\n",
    "                    self.patches_info.append({\n",
    "                        'img_idx': img_idx,\n",
    "                        'img_path': img_path,\n",
    "                        'x': x,\n",
    "                        'y': y,\n",
    "                        'patch_size': self.patch_size\n",
    "                    })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.patches_info)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        patch_info = self.patches_info[idx]\n",
    "        \n",
    "        # Load only the required patch (memory efficient for large images)\n",
    "        if Path(patch_info['img_path']).exists():\n",
    "            img = np.array(Image.open(patch_info['img_path']))\n",
    "            x, y = patch_info['x'], patch_info['y']\n",
    "            patch = img[y:y+self.patch_size, x:x+self.patch_size]\n",
    "        else:\n",
    "            # Dummy patch for testing\n",
    "            patch = np.random.randint(0, 255, (self.patch_size, self.patch_size, 3), dtype=np.uint8)\n",
    "        \n",
    "        if self.transform:\n",
    "            patch = self.transform(patch)\n",
    "        else:\n",
    "            patch = torch.FloatTensor(patch).permute(2, 0, 1) / 255.0\n",
    "        \n",
    "        return patch, patch_info\n",
    "\n",
    "# Create transforms and test dataset\n",
    "large_scale_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Test with dummy large area paths\n",
    "test_large_area_paths = [\"large_area_1.tif\", \"large_area_2.tif\"]\n",
    "\n",
    "dataset = LargeScaleDataset(\n",
    "    test_large_area_paths, \n",
    "    patch_size=512, \n",
    "    overlap=0.1, \n",
    "    transform=large_scale_transforms\n",
    ")\n",
    "\n",
    "print(f\"Created large-scale dataset with {len(dataset)} patches\")\n",
    "print(f\"Dataset ready for 500km x 500km processing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f269a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Large-scale inference (500km x 500km): 100%|██████████| 5/5 [00:01<00:00,  4.93it/s, GPU_Memory_GB=0.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory-efficient inference test completed!\n",
      "Generated 10 predictions efficiently\n",
      "Using UNetWithHeight model with dual outputs (segmentation + height)\n",
      "Dummy data patches working correctly for testing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Memory-Efficient Inference for Large Areas\n",
    "def memory_efficient_large_scale_inference(model, dataloader, device, use_mixed_precision=True):\n",
    "    \"\"\"Memory-efficient inference optimized for processing 500km x 500km areas\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    patch_infos = []\n",
    "    \n",
    "    # Clear GPU cache before processing\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Use automatic mixed precision for memory efficiency\n",
    "    scaler = GradScaler() if use_mixed_precision else None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"Large-scale inference (500km x 500km)\")\n",
    "        \n",
    "        for batch_idx, (images, batch_patch_infos) in enumerate(pbar):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            \n",
    "            # Use mixed precision to save memory\n",
    "            if use_mixed_precision:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    # Handle dual output from UNetWithHeight (segmentation, height_map)\n",
    "                    if isinstance(outputs, tuple):\n",
    "                        segmentation, height_map = outputs\n",
    "                        # Use segmentation for building detection\n",
    "                        outputs = torch.sigmoid(segmentation)\n",
    "                    else:\n",
    "                        outputs = torch.sigmoid(outputs)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                # Handle dual output from UNetWithHeight (segmentation, height_map)\n",
    "                if isinstance(outputs, tuple):\n",
    "                    segmentation, height_map = outputs\n",
    "                    # Use segmentation for building detection\n",
    "                    outputs = torch.sigmoid(segmentation)\n",
    "                else:\n",
    "                    outputs = torch.sigmoid(outputs)\n",
    "            \n",
    "            # Move to CPU immediately to free GPU memory\n",
    "            batch_predictions = outputs.cpu().numpy()\n",
    "            predictions.extend(batch_predictions)\n",
    "            patch_infos.extend(batch_patch_infos)\n",
    "            \n",
    "            # Memory management for large-scale processing\n",
    "            if batch_idx % 10 == 0:  # Clear cache every 10 batches\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            # Update progress bar with memory info\n",
    "            if torch.cuda.is_available():\n",
    "                memory_used = torch.cuda.memory_allocated() / 1024**3\n",
    "                pbar.set_postfix({'GPU_Memory_GB': f'{memory_used:.1f}'})\n",
    "    \n",
    "    return predictions, patch_infos\n",
    "\n",
    "# Test memory-efficient inference\n",
    "if model_loaded:\n",
    "    # Create test dataloader\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=2, \n",
    "        shuffle=False, \n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    # Test with small subset\n",
    "    small_subset = torch.utils.data.Subset(dataset, range(min(10, len(dataset))))\n",
    "    small_dataloader = DataLoader(small_subset, batch_size=2, shuffle=False)\n",
    "    \n",
    "    test_predictions, test_patch_infos = memory_efficient_large_scale_inference(\n",
    "        model, small_dataloader, device\n",
    "    )\n",
    "    \n",
    "    print(f\"Memory-efficient inference test completed!\")\n",
    "    print(f\"Generated {len(test_predictions)} predictions efficiently\")\n",
    "    print(f\"Using UNetWithHeight model with dual outputs (segmentation + height)\")\n",
    "    print(f\"Dummy data patches working correctly for testing!\")\n",
    "else:\n",
    "    print(\"Skipping inference test - model not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a49501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large area tiling plan: 108 x 108 = 11664 tiles\n",
      "Estimated processing time: 1166.4 seconds\n",
      "Tiling strategy test completed:\n",
      "  Image shape: (50000, 50000, 3)\n",
      "  Number of tiles: 11664\n",
      "  Optimal batch size: 4\n"
     ]
    }
   ],
   "source": [
    "# Tiling Strategy for 500km x 500km Areas\n",
    "class LargeAreaTilingStrategy:\n",
    "    \"\"\"Advanced tiling strategy specifically designed for 500km x 500km areas\"\"\"\n",
    "    \n",
    "    def __init__(self, patch_size=512, overlap=0.1, max_memory_gb=4):\n",
    "        self.patch_size = patch_size\n",
    "        self.overlap = overlap\n",
    "        self.max_memory_gb = max_memory_gb\n",
    "        self.step = int(patch_size * (1 - overlap))\n",
    "    \n",
    "    def calculate_optimal_batch_size_for_large_areas(self, estimated_image_size_gb):\n",
    "        \"\"\"Calculate optimal batch size for very large satellite imagery\"\"\"\n",
    "        # Conservative memory estimation for 500km x 500km processing\n",
    "        patch_memory_mb = (self.patch_size * self.patch_size * 3 * 4) / (1024 * 1024)\n",
    "        \n",
    "        # Reserve memory for model and other operations\n",
    "        available_memory_mb = (self.max_memory_gb * 1024) - 1000  # Reserve 1GB\n",
    "        \n",
    "        # Calculate safe batch size\n",
    "        optimal_batch_size = max(1, int(available_memory_mb / (patch_memory_mb * 3)))  # Factor of 3 for safety\n",
    "        \n",
    "        return min(optimal_batch_size, 4)  # Cap for large-area processing\n",
    "    \n",
    "    def create_large_area_tiling_plan(self, image_shape):\n",
    "        \"\"\"Create tiling plan optimized for 500km x 500km areas\"\"\"\n",
    "        h, w = image_shape[:2]\n",
    "        \n",
    "        # Calculate total number of tiles for large area\n",
    "        tiles_x = (w - self.patch_size) // self.step + 1\n",
    "        tiles_y = (h - self.patch_size) // self.step + 1\n",
    "        total_tiles = tiles_x * tiles_y\n",
    "        \n",
    "        print(f\"Large area tiling plan: {tiles_x} x {tiles_y} = {total_tiles} tiles\")\n",
    "        print(f\"Estimated processing time: {total_tiles * 0.1:.1f} seconds\")\n",
    "        \n",
    "        tiles = []\n",
    "        for y in range(0, h - self.patch_size + 1, self.step):\n",
    "            for x in range(0, w - self.patch_size + 1, self.step):\n",
    "                tiles.append({\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'x_end': min(x + self.patch_size, w),\n",
    "                    'y_end': min(y + self.patch_size, h)\n",
    "                })\n",
    "        \n",
    "        return tiles\n",
    "    \n",
    "    def reconstruct_large_area_from_tiles(self, predictions, tiles, original_shape):\n",
    "        \"\"\"Reconstruct 500km x 500km area from overlapping tiles with blending\"\"\"\n",
    "        h, w = original_shape[:2]\n",
    "        \n",
    "        # Initialize output arrays\n",
    "        output = np.zeros((h, w), dtype=np.float32)\n",
    "        weight_map = np.zeros((h, w), dtype=np.float32)\n",
    "        \n",
    "        # Create blending weights for seamless large-area reconstruction\n",
    "        blend_weights = self._create_large_area_blend_weights(self.patch_size)\n",
    "        \n",
    "        print(f\"Reconstructing large area: {h} x {w} pixels from {len(predictions)} tiles\")\n",
    "        \n",
    "        for pred, tile in zip(predictions, tiles):\n",
    "            if len(pred.shape) == 3:\n",
    "                pred_tile = pred[0]  # Remove batch dimension\n",
    "            else:\n",
    "                pred_tile = pred\n",
    "            \n",
    "            x, y = tile['x'], tile['y']\n",
    "            x_end, y_end = tile['x_end'], tile['y_end']\n",
    "            \n",
    "            # Handle edge cases for large areas\n",
    "            tile_h, tile_w = pred_tile.shape\n",
    "            actual_h = min(tile_h, y_end - y)\n",
    "            actual_w = min(tile_w, x_end - x)\n",
    "            \n",
    "            # Apply blending weights\n",
    "            weighted_pred = pred_tile[:actual_h, :actual_w] * blend_weights[:actual_h, :actual_w]\n",
    "            weight_tile = blend_weights[:actual_h, :actual_w]\n",
    "            \n",
    "            # Accumulate in output\n",
    "            output[y:y+actual_h, x:x+actual_w] += weighted_pred\n",
    "            weight_map[y:y+actual_h, x:x+actual_w] += weight_tile\n",
    "        \n",
    "        # Normalize by weights\n",
    "        output = np.divide(output, weight_map, out=np.zeros_like(output), where=weight_map!=0)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _create_large_area_blend_weights(self, patch_size):\n",
    "        \"\"\"Create blending weights optimized for large-area seamless reconstruction\"\"\"\n",
    "        # Create smoother blending for large areas\n",
    "        center = patch_size // 2\n",
    "        y, x = np.ogrid[:patch_size, :patch_size]\n",
    "        \n",
    "        # Distance from center with smoother falloff\n",
    "        dist_from_center = np.sqrt((x - center)**2 + (y - center)**2)\n",
    "        max_dist = np.sqrt(2) * center\n",
    "        \n",
    "        # Smoother weights for large-area processing\n",
    "        weights = np.cos(np.pi * dist_from_center / (2 * max_dist))\n",
    "        weights = np.clip(weights, 0.2, 1.0)  # Ensure minimum weight\n",
    "        \n",
    "        return weights\n",
    "\n",
    "# Test tiling strategy\n",
    "large_area_tiling = LargeAreaTilingStrategy(patch_size=512, overlap=0.1, max_memory_gb=4)\n",
    "\n",
    "# Test with 500km x 500km simulation\n",
    "large_image_shape = (50000, 50000, 3)  # 500km x 500km at 10m resolution\n",
    "tiles = large_area_tiling.create_large_area_tiling_plan(large_image_shape)\n",
    "optimal_batch_size = large_area_tiling.calculate_optimal_batch_size_for_large_areas(estimated_image_size_gb=7.5)\n",
    "\n",
    "print(f\"Tiling strategy test completed:\")\n",
    "print(f\"  Image shape: {large_image_shape}\")\n",
    "print(f\"  Number of tiles: {len(tiles)}\")\n",
    "print(f\"  Optimal batch size: {optimal_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e03e86b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating seamless mosaic for large area: 1024 x 1024 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mosaicking large area: 100%|██████████| 2/2 [00:00<00:00, 450.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seamless large-area mosaicking completed!\n",
      "Mosaicking test completed!\n",
      "Created seamless mosaic of shape (1024, 1024)\n",
      "Quality metrics:\n",
      "  mean_confidence: 0.0007449278491549194\n",
      "  std_confidence: 0.0013807985233142972\n",
      "  coverage_percentage: 0.0\n",
      "  num_buildings: 0\n",
      "  avg_building_area: 0\n",
      "  total_building_area: 0\n",
      "  building_density_per_km2: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Scene Mosaicking and Seamless Integration\n",
    "def seamless_large_area_mosaicking(tile_predictions, tile_positions, output_shape, blend_border=64):\n",
    "    \"\"\"Advanced mosaicking for seamless integration of 500km x 500km areas\"\"\"\n",
    "    \n",
    "    h, w = output_shape[:2]\n",
    "    mosaic = np.zeros((h, w), dtype=np.float32)\n",
    "    weight_map = np.zeros((h, w), dtype=np.float32)\n",
    "    \n",
    "    print(f\"Creating seamless mosaic for large area: {h} x {w} pixels\")\n",
    "    \n",
    "    def create_advanced_feather_weights(tile_shape, border_size):\n",
    "        \"\"\"Create advanced feathering weights for large-area seamless blending\"\"\"\n",
    "        th, tw = tile_shape\n",
    "        weights = np.ones((th, tw), dtype=np.float32)\n",
    "        \n",
    "        # Apply sophisticated feathering to edges\n",
    "        for i in range(border_size):\n",
    "            alpha = (i + 1) / border_size\n",
    "            # Smooth transition using cosine function\n",
    "            weight = 0.5 * (1 + np.cos(np.pi * (1 - alpha)))\n",
    "            \n",
    "            # Apply to all edges\n",
    "            weights[i, :] *= weight  # Top\n",
    "            weights[-(i+1), :] *= weight  # Bottom\n",
    "            weights[:, i] *= weight  # Left\n",
    "            weights[:, -(i+1)] *= weight  # Right\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    # Process each tile with advanced blending\n",
    "    for prediction, position in tqdm(zip(tile_predictions, tile_positions), \n",
    "                                   desc=\"Mosaicking large area\", \n",
    "                                   total=len(tile_predictions)):\n",
    "        x, y = position['x'], position['y']\n",
    "        \n",
    "        # Get tile dimensions\n",
    "        if len(prediction.shape) == 3:\n",
    "            pred_tile = prediction[0]\n",
    "        else:\n",
    "            pred_tile = prediction\n",
    "        \n",
    "        th, tw = pred_tile.shape\n",
    "        \n",
    "        # Create advanced feathering weights\n",
    "        feather_weights = create_advanced_feather_weights((th, tw), blend_border)\n",
    "        \n",
    "        # Calculate placement area (handle large image boundaries)\n",
    "        x_end = min(x + tw, w)\n",
    "        y_end = min(y + th, h)\n",
    "        actual_tw = x_end - x\n",
    "        actual_th = y_end - y\n",
    "        \n",
    "        # Place tile in mosaic with advanced blending\n",
    "        mosaic[y:y_end, x:x_end] += pred_tile[:actual_th, :actual_tw] * feather_weights[:actual_th, :actual_tw]\n",
    "        weight_map[y:y_end, x:x_end] += feather_weights[:actual_th, :actual_tw]\n",
    "    \n",
    "    # Normalize by weights for seamless result\n",
    "    mosaic = np.divide(mosaic, weight_map, out=np.zeros_like(mosaic), where=weight_map!=0)\n",
    "    \n",
    "    print(\"Seamless large-area mosaicking completed!\")\n",
    "    return mosaic\n",
    "\n",
    "def assess_large_area_quality(prediction, return_detailed_metrics=True):\n",
    "    \"\"\"Quality assessment specifically for large-area predictions\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Basic large-area statistics\n",
    "    metrics['mean_confidence'] = np.mean(prediction)\n",
    "    metrics['std_confidence'] = np.std(prediction)\n",
    "    metrics['coverage_percentage'] = (prediction > 0.5).sum() / prediction.size * 100\n",
    "    \n",
    "    # Large-area specific metrics\n",
    "    binary_pred = (prediction > 0.5).astype(np.uint8)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_pred)\n",
    "    \n",
    "    if num_labels > 1:\n",
    "        building_areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "        metrics['num_buildings'] = len(building_areas)\n",
    "        metrics['avg_building_area'] = np.mean(building_areas)\n",
    "        metrics['total_building_area'] = np.sum(building_areas)\n",
    "        metrics['building_density_per_km2'] = len(building_areas) / (prediction.size / 1e6)  # Assuming 10m resolution\n",
    "    else:\n",
    "        metrics['num_buildings'] = 0\n",
    "        metrics['avg_building_area'] = 0\n",
    "        metrics['total_building_area'] = 0\n",
    "        metrics['building_density_per_km2'] = 0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Test mosaicking with available predictions\n",
    "if model_loaded and 'test_predictions' in locals():\n",
    "    # Create test positions for mosaicking\n",
    "    test_positions = [{'x': 0, 'y': 0}, {'x': 256, 'y': 0}][:len(test_predictions)]\n",
    "    \n",
    "    if len(test_positions) > 0:\n",
    "        test_mosaic = seamless_large_area_mosaicking(\n",
    "            test_predictions[:len(test_positions)], \n",
    "            test_positions, \n",
    "            (1024, 1024)\n",
    "        )\n",
    "        \n",
    "        # Quality assessment\n",
    "        quality_metrics = assess_large_area_quality(test_mosaic)\n",
    "        \n",
    "        print(f\"Mosaicking test completed!\")\n",
    "        print(f\"Created seamless mosaic of shape {test_mosaic.shape}\")\n",
    "        print(f\"Quality metrics:\")\n",
    "        for key, value in quality_metrics.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"Mosaicking test skipped - no predictions available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c56a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask client for large-area processing started with 4 workers\n",
      "Dashboard available at: http://127.0.0.1:8787/status\n",
      "Dask client successfully initialized for distributed processing!\n",
      "Cluster info: <Client: 'tcp://127.0.0.1:56007' processes=4 threads=8, memory=11.18 GiB>\n"
     ]
    }
   ],
   "source": [
    "# Dask Client Setup for Distributed Processing\n",
    "def setup_dask_client_for_large_areas(n_workers=None):\n",
    "    \"\"\"Setup Dask client optimized for 500km x 500km processing\"\"\"\n",
    "    if n_workers is None:\n",
    "        n_workers = min(mp.cpu_count(), 4)  # Conservative for large-area processing\n",
    "    \n",
    "    try:\n",
    "        client = Client(\n",
    "            processes=True, \n",
    "            threads_per_worker=2, \n",
    "            n_workers=n_workers,\n",
    "            memory_limit='3GB',  # Conservative memory limit\n",
    "            dashboard_address=':8787'\n",
    "        )\n",
    "        print(f\"Dask client for large-area processing started with {n_workers} workers\")\n",
    "        print(f\"Dashboard available at: {client.dashboard_link}\")\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to start Dask client: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test Dask client setup\n",
    "dask_client = setup_dask_client_for_large_areas()\n",
    "\n",
    "if dask_client:\n",
    "    print(\"Dask client successfully initialized for distributed processing!\")\n",
    "    print(f\"Cluster info: {dask_client}\")\n",
    "else:\n",
    "    print(\"Dask client setup failed - will use sequential processing fallback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "607673ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Distributed Processing with Modular Model Loading\n",
    "def distributed_tile_processing_v2(tiles, model_path, batch_size=10, n_workers=4, dask_client=None):\n",
    "    \"\"\"Process tiles using distributed Dask workers with modular model loading\"\"\"\n",
    "    \n",
    "    # Use the global client if not provided\n",
    "    if dask_client is None:\n",
    "        try:\n",
    "            from dask.distributed import get_client\n",
    "            dask_client = get_client()\n",
    "        except Exception:\n",
    "            print(\"Error: No Dask client available. Please start a Dask client first.\")\n",
    "            return []\n",
    "    \n",
    "    # Import the modular loader in the distributed context\n",
    "    def process_tile_batch(batch_tiles):\n",
    "        \"\"\"Process a batch of tiles in a Dask worker\"\"\"\n",
    "        # Import the modular model loader\n",
    "        from dask_model_loader import process_tile_with_model\n",
    "        \n",
    "        results = []\n",
    "        for tile_data, tile_info in batch_tiles:\n",
    "            result = process_tile_with_model(model_path, tile_data, tile_info)\n",
    "            results.append(result)\n",
    "        return results\n",
    "    \n",
    "    # Split tiles into batches\n",
    "    tile_batches = []\n",
    "    for i in range(0, len(tiles), batch_size):\n",
    "        batch = tiles[i:i+batch_size]\n",
    "        tile_batches.append(batch)\n",
    "    \n",
    "    print(f\"Processing {len(tiles)} tiles in {len(tile_batches)} batches using {n_workers} workers\")\n",
    "    \n",
    "    # Submit batches to Dask workers\n",
    "    futures = []\n",
    "    for batch in tile_batches:\n",
    "        future = dask_client.submit(process_tile_batch, batch)\n",
    "        futures.append(future)\n",
    "    \n",
    "    # Collect results\n",
    "    all_results = []\n",
    "    for i, future in enumerate(futures):\n",
    "        try:\n",
    "            batch_results = future.result(timeout=300)  # 5 minute timeout per batch\n",
    "            all_results.extend(batch_results)\n",
    "            print(f\"✓ Completed batch {i+1}/{len(futures)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Batch {i+1} failed: {e}\")\n",
    "            # Add failed results for this batch\n",
    "            batch_size_actual = len(tile_batches[i])\n",
    "            for j in range(batch_size_actual):\n",
    "                all_results.append({\n",
    "                    'prediction': np.zeros((512, 512), dtype=np.float32),\n",
    "                    'tile_info': tile_batches[i][j][1],  # tile_info\n",
    "                    'status': 'batch_failed'\n",
    "                })\n",
    "    \n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "003badc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing improved distributed processing with modular model loading...\n",
      "Processing 20 tiles in 4 batches using 2 workers\n",
      "✓ Completed batch 1/4\n",
      "✓ Completed batch 1/4\n",
      "✓ Completed batch 2/4\n",
      "✓ Completed batch 3/4\n",
      "✓ Completed batch 4/4\n",
      "\n",
      "Distributed processing completed!\n",
      "Processed 20 tiles\n",
      "Successful predictions: 20\n",
      "Failed predictions: 0\n",
      "Prediction shapes: {(512, 512)}\n",
      "Sample prediction ranges: [(np.float32(1.2990328e-06), np.float32(0.03317861)), (np.float32(5.8671765e-07), np.float32(0.059099343)), (np.float32(3.1131524e-06), np.float32(0.022919338))]\n",
      "✓ Completed batch 2/4\n",
      "✓ Completed batch 3/4\n",
      "✓ Completed batch 4/4\n",
      "\n",
      "Distributed processing completed!\n",
      "Processed 20 tiles\n",
      "Successful predictions: 20\n",
      "Failed predictions: 0\n",
      "Prediction shapes: {(512, 512)}\n",
      "Sample prediction ranges: [(np.float32(1.2990328e-06), np.float32(0.03317861)), (np.float32(5.8671765e-07), np.float32(0.059099343)), (np.float32(3.1131524e-06), np.float32(0.022919338))]\n"
     ]
    }
   ],
   "source": [
    "# Test the Improved Distributed Processing\n",
    "print(\"Testing improved distributed processing with modular model loading...\")\n",
    "\n",
    "# Use dummy data for testing\n",
    "test_tiles = []\n",
    "for i in range(20):  # Test with 20 tiles\n",
    "    dummy_tile = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)\n",
    "    tile_info = {'row': i//5, 'col': i%5, 'tile_id': f'test_tile_{i}'}\n",
    "    test_tiles.append((dummy_tile, tile_info))\n",
    "\n",
    "# Process with improved distributed workers\n",
    "model_path = r'height_analysis_output\\best_height_model.pth'\n",
    "distributed_results_v2 = distributed_tile_processing_v2(test_tiles, model_path, batch_size=5, n_workers=2)\n",
    "\n",
    "print(f\"\\nDistributed processing completed!\")\n",
    "print(f\"Processed {len(distributed_results_v2)} tiles\")\n",
    "print(f\"Successful predictions: {sum(1 for r in distributed_results_v2 if r['status'] == 'success')}\")\n",
    "print(f\"Failed predictions: {sum(1 for r in distributed_results_v2 if r['status'] != 'success')}\")\n",
    "\n",
    "# Verify prediction quality\n",
    "successful_preds = [r['prediction'] for r in distributed_results_v2 if r['status'] == 'success']\n",
    "if successful_preds:\n",
    "    pred_shapes = [p.shape for p in successful_preds]\n",
    "    pred_ranges = [(p.min(), p.max()) for p in successful_preds[:3]]\n",
    "    print(f\"Prediction shapes: {set(pred_shapes)}\")\n",
    "    print(f\"Sample prediction ranges: {pred_ranges}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No successful predictions - investigating...\")\n",
    "    # Show some error details\n",
    "    error_statuses = [r['status'] for r in distributed_results_v2 if r['status'] != 'success']\n",
    "    print(f\"Error statuses: {set(error_statuses)}\")\n",
    "    \n",
    "    # Check if modular loader file exists\n",
    "    import os\n",
    "    if os.path.exists('dask_model_loader.py'):\n",
    "        print(\"Modular loader file exists\")\n",
    "    else:\n",
    "        print(\"Modular loader file missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd36eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Large-Area Processing Results\n",
    "def visualize_large_area_results(original_shape, prediction, quality_metrics, save_path=None):\n",
    "    \"\"\"Visualize large-area processing results\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Original area size visualization\n",
    "    axes[0, 0].text(0.5, 0.5, f'Large Area Processing\\n{original_shape[0]} x {original_shape[1]} pixels\\n≈ {original_shape[0]*10/1000:.1f} x {original_shape[1]*10/1000:.1f} km', \n",
    "                   ha='center', va='center', fontsize=12, transform=axes[0, 0].transAxes)\n",
    "    axes[0, 0].set_title('Processing Area Info')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Prediction visualization\n",
    "    if prediction is not None:\n",
    "        axes[0, 1].imshow(prediction, cmap='hot', interpolation='nearest')\n",
    "        axes[0, 1].set_title('Large Area Prediction')\n",
    "        axes[0, 1].axis('off')\n",
    "    \n",
    "    # Quality metrics\n",
    "    axes[1, 0].axis('off')\n",
    "    if quality_metrics:\n",
    "        metrics_text = f\"\"\"\n",
    "Large Area Quality Metrics:\n",
    "\n",
    "Buildings Detected: {quality_metrics.get('num_buildings', 0)}\n",
    "Coverage: {quality_metrics.get('coverage_percentage', 0):.2f}%\n",
    "Avg Building Area: {quality_metrics.get('avg_building_area', 0):.2f} px²\n",
    "Building Density: {quality_metrics.get('building_density_per_km2', 0):.2f} per km²\n",
    "Mean Confidence: {quality_metrics.get('mean_confidence', 0):.3f}\n",
    "        \"\"\"\n",
    "        axes[1, 0].text(0.1, 0.9, metrics_text, transform=axes[1, 0].transAxes,\n",
    "                        fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    # Processing summary\n",
    "    axes[1, 1].axis('off')\n",
    "    axes[1, 1].text(0.1, 0.9,transform=axes[1, 1].transAxes, fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Visualization saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "output_dir = Path(\"large_area_test_output\")\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Visualize results if available\n",
    "if 'test_mosaic' in locals():\n",
    "    visualize_large_area_results(\n",
    "        original_shape=(1024, 1024),\n",
    "        prediction=test_mosaic,\n",
    "        quality_metrics=quality_metrics,\n",
    "        save_path=output_dir / \"large_area_results.png\"\n",
    "    )\n",
    "elif 'test_predictions' in locals() and len(test_predictions) > 0:\n",
    "    # Create a simple visualization with first prediction\n",
    "    sample_prediction = test_predictions[0][0] if len(test_predictions[0].shape) == 3 else test_predictions[0]\n",
    "    sample_metrics = assess_large_area_quality(sample_prediction)\n",
    "    \n",
    "    visualize_large_area_results(\n",
    "        original_shape=sample_prediction.shape,\n",
    "        prediction=sample_prediction,\n",
    "        quality_metrics=sample_metrics,\n",
    "        save_path=output_dir / \"sample_results.png\"\n",
    "    )\n",
    "# Note: Visualization function ready for use when data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12505e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask client closed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Clean up resources and final summary\n",
    "if 'dask_client' in locals() and dask_client:\n",
    "    dask_client.close()\n",
    "    print(\"Dask client closed\")\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
